{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242585b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence-transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c585453c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# 1. Load model\n",
    "model = SentenceTransformer(\"intfloat/e5-small-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbbd324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Example sentences (pretend these came from a PDF)\n",
    "sentences = [\n",
    "    \"Machine learning is a field of artificial intelligence.\",\n",
    "    \"Transformers are deep learning models used in NLP.\",\n",
    "    \"Sentence embeddings capture semantic meaning of text.\",\n",
    "    \"Vector databases are used for similarity search.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891814e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# E5 models expect \"passage:\" and \"query:\" prefixes\n",
    "passages = [f\"passage: {s}\" for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9538e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Embed passages\n",
    "passage_embeddings = model.encode(passages, normalize_embeddings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c536337f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Query\n",
    "query = \"How do we represent text meaning numerically?\"\n",
    "query_embedding = model.encode(\n",
    "    f\"query: {query}\",\n",
    "    normalize_embeddings=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230beba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Similarity search\n",
    "scores = util.cos_sim(query_embedding, passage_embeddings)[0]\n",
    "\n",
    "# 6. Get best match\n",
    "best_idx = scores.argmax()\n",
    "print(\"Query:\", query)\n",
    "print(\"Most relevant sentence:\", sentences[best_idx])\n",
    "print(\"Similarity score:\", float(scores[best_idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b343f313",
   "metadata": {},
   "source": [
    "## pdf loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1acb40f",
   "metadata": {},
   "source": [
    "!pip install pypdf langchain install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b01a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fad2c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9a0cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.document_loaders import PyPDFLoader\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# 1. Load PDF\n",
    "loader = PyPDFLoader(\"/content/RITIKA KUMARI RESUMEE.pdf\")   # <-- your PDF path\n",
    "docs = loader.load()\n",
    "\n",
    "# Take only a few lines for simplicity (3–5 sentences)\n",
    "sentences = [\n",
    "    doc.page_content.strip().replace(\"\\n\", \" \")\n",
    "    for doc in docs[:5]\n",
    "]\n",
    "\n",
    "# 2. Load embedding model\n",
    "model = SentenceTransformer(\"intfloat/e5-small-v2\")\n",
    "\n",
    "# E5 requires prefixes\n",
    "passages = [f\"passage: {s}\" for s in sentences]\n",
    "\n",
    "# 3. Embed PDF sentences\n",
    "passage_embeddings = model.encode(\n",
    "    passages,\n",
    "    normalize_embeddings=True\n",
    ")\n",
    "\n",
    "# 4. Query\n",
    "query = \"hey how are u?\"\n",
    "query_embedding = model.encode(\n",
    "    f\"query: {query}\",\n",
    "    normalize_embeddings=True\n",
    ")\n",
    "\n",
    "# 5. Similarity search\n",
    "scores = util.cos_sim(query_embedding, passage_embeddings)[0]\n",
    "best_idx = scores.argmax()\n",
    "\n",
    "# 6. Result\n",
    "print(\"Query:\", query)\n",
    "print(\"\\nMost relevant sentence:\")\n",
    "print(sentences[best_idx])\n",
    "print(\"\\nSimilarity score:\", float(scores[best_idx]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a116829a",
   "metadata": {},
   "source": [
    "## increasing the doc size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb4ce03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Load PDF\n",
    "loader = PyPDFLoader(\"/content/RITIKA KUMARI RESUMEE.pdf\")\n",
    "docs = loader.load()\n",
    "\n",
    "# Simple sentence-level chunks\n",
    "sentences = []\n",
    "for doc in docs:\n",
    "    for line in doc.page_content.split(\"\\n\"):\n",
    "        line = line.strip()\n",
    "        if len(line) > 30:\n",
    "            sentences.append(line)\n",
    "\n",
    "# Load model\n",
    "model = SentenceTransformer(\"intfloat/e5-small-v2\")\n",
    "\n",
    "passages = [f\"passage: {s}\" for s in sentences]\n",
    "passage_embeddings = model.encode(passages, normalize_embeddings=True)\n",
    "\n",
    "# Query (resume-relevant)\n",
    "query = \"• Benchmarked in-house TTS and ASR models against state-of-the-art baselines, designing custom metrics for speech quality, intelligibility, and accuracy.\"\n",
    "query_embedding = model.encode(f\"query: {query}\", normalize_embeddings=True)\n",
    "\n",
    "scores = util.cos_sim(query_embedding, passage_embeddings)[0]\n",
    "best_idx = scores.argmax()\n",
    "\n",
    "print(\"Query:\", query)\n",
    "print(\"\\nBest match:\")\n",
    "print(sentences[best_idx])\n",
    "print(\"Score:\", float(scores[best_idx]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ana",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
